{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW0115_2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvGx9VrlThkXYqx7sxbLKi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BamByeol/learning-ML/blob/HW220115/HW0115_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axVDQ6wdCbYk"
      },
      "outputs": [],
      "source": [
        "#자동 미분 실습하기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "w = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "y = w ** 2\n",
        "z = 2*y + 5\n",
        "\n",
        "z.backward()\n",
        "\n",
        "print('수식을 w로 미분한 값 :',format(w.grad))"
      ],
      "metadata": {
        "id": "AvtAN30wC0hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#03.다중선형회귀 구현하기"
      ],
      "metadata": {
        "id": "Cr5kZfycDfNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn. functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "id": "UpAwlmjJD3x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련데이터\n",
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "#가중치(W)와 편향(b)를 선언 / x가 3개이므로 가중치도 3개 선언\n",
        "w1 = torch.zeros(1, requires_grad=True)\n",
        "w2 = torch.zeros(1, requires_grad=True)\n",
        "w3 = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)"
      ],
      "metadata": {
        "id": "P2FD-qGMECkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 1000 #경사하강법 1000회 반복\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산 / x_train의 갯수만큼 W와 곱해주도록 작성\n",
        "    hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "id": "ROPWfW5CETzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#행렬의 곱셈과정에서 이루어지는 벡터 연산인 내적을 편하게 하기 위해 코드 다시 작성\n",
        "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
        "                               [93,  88,  93], \n",
        "                               [89,  91,  80], \n",
        "                               [96,  98,  100],   \n",
        "                               [73,  66,  70]])  \n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
        "\n",
        "# 가중치와 편향 선언\n",
        "W = torch.zeros((3, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "hypothesis = x_train.matmul(W) + b #가설을 간단하게 정의 가능\n",
        "\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    # 편향 b는 브로드 캐스팅되어 각 샘플에 더해집니다.\n",
        "    hypothesis = x_train.matmul(W) + b\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "id": "51PuRESpF4B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#파이토치에서 구현되어져있는 함수를 사용하여 다중 선형 회귀 구현하기\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# 데이터\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "# 모델을 선언 및 초기화. 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
        "model = nn.Linear(3,1)\n",
        "\n",
        "print(list(model.parameters()))\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) \n",
        "\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "    # model(x_train)은 model.forward(x_train)와 동일함.\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
        "\n",
        "    # cost로 H(x) 개선하는 부분\n",
        "    # gradient를 0으로 초기화\n",
        "    optimizer.zero_grad()\n",
        "    # 비용 함수를 미분하여 gradient 계산\n",
        "    cost.backward()\n",
        "    # W와 b를 업데이트\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "    # 100번마다 로그 출력\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, cost.item()\n",
        "      ))"
      ],
      "metadata": {
        "id": "IYXiQ7koJDb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#W와 b의 값도 최적화 되었는지 x에 임의의 값을 넣어 확인\n",
        "# 임의의 입력 [73, 80, 75]를 선언\n",
        "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
        "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
        "pred_y = model(new_var) \n",
        "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
      ],
      "metadata": {
        "id": "ZOSceRF-JX40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 후 3개의 W와 b의 값을 출력\n",
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "id": "idyFIds5JgqP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}