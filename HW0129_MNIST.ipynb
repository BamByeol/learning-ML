{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW0129_MNIST.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjgtbhdcF2YmD52uIH386v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BamByeol/learning-ML/blob/HW220129/HW0129_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7wWYx_6j_Hz"
      },
      "outputs": [],
      "source": [
        "#소프트맥스회귀로 MNIST 구현 05.05\n",
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available() # GPU를 사용가능하면 True, 아니라면 False를 리턴\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\n",
        "print(\"다음 기기로 학습합니다:\", device)\n",
        "#result\n",
        "#다음 기기로 학습합니다: cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#랜덤시드 고정\n",
        "# for reproducibility\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "#하이퍼파라미터를 변수로 둠\n",
        "# hyperparameters\n",
        "training_epochs = 1000\n",
        "batch_size = 100"
      ],
      "metadata": {
        "id": "TdKWJ-Fbktoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/', # root는 MNIST 데이터를 다운로드 받을 경로\n",
        "                          train=True, # train은 인자로 True를 주면, MNIST의 훈련 데이터를 리턴받으며 False를 주면 테스트 데이터를 리턴받음\n",
        "                          transform=transforms.ToTensor(), # transform은 현재 데이터를 파이토치 텐서로 변환 \n",
        "                          download=True) # download는 해당 경로에 MNIST 데이터가 없다면 다운로드 받겠다는 의미\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)\n",
        "\n",
        "# dataset loader 사용\n",
        "data_loader = DataLoader(dataset=mnist_train, # dataset은 로드할 대상을 의미\n",
        "                                          batch_size=100, # 배치 크기는 100\n",
        "                                          shuffle=True, # shuffle은 매 에포크마다 미니 배치를 셔플할 것인지의 여부\n",
        "                                          drop_last=True) # 마지막 배치를 버릴 것인지를 의미\n",
        "# drop_last를 하는 이유를 이해하기 위해서 1,000개의 데이터가 있다고 했을 때, 배치 크기가 128이라고 하자. \n",
        "#1,000을 128로 나누면 총 7개가 나오고 나머지로 104개가 남습니다. 이때 104개를 마지막 배치로 한다고 하였을 때 128개를 충족하지 못하였으므로 104개를 그냥 버릴 수도 있음. \n",
        "#이때 마지막 배치를 버리려면 drop_last=True를 해주면 됨. \n",
        "#이는 다른 미니 배치보다 개수가 적은 마지막 배치를 경사 하강법에 사용하여 마지막 배치가 상대적으로 과대 평가되는 현상을 막아줌.\n",
        "\n",
        "# 모델설계 -  MNIST data image of shape 28 * 28 = 784\n",
        "linear = nn.Linear(784, 10, bias=True).to(device) #to() 함수는 연산을 어디서 수행할지를 정함 / 아무것도 지정하지 않은 경우에는 CPU 연산 / bias는 편향 b를 사용할 것인지를 나타냅니다. 기본값은 True\n",
        "\n",
        "# 비용 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss().to(device) # 내부적으로 소프트맥스 함수를 포함하고 있음.\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1) #이전에   torch.nn.functional.cross_entropy()를 사용 \n",
        "                                                         #여기서는 torch.nn.CrossEntropyLoss()을 사용 \n",
        "                                                         #둘 다 파이토치에서 제공하는 크로스 엔트로피 함수로 둘 다 소프트맥스 함수를 포함\n",
        "\n",
        "for epoch in range(training_epochs): # 앞서 training_epochs의 값은 15로 지정함.\n",
        "    avg_cost = 0\n",
        "    total_batch = len(data_loader)\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        # 배치 크기가 100이므로 아래의 연산에서 X는 (100, 784)의 텐서가 된다.\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        # 레이블은 원-핫 인코딩이 된 상태가 아니라 0 ~ 9의 정수.\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = linear(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning finished')"
      ],
      "metadata": {
        "id": "TJRJXcbfk5LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터를 사용하여 모델을 테스트한다.\n",
        "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
        "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = linear(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())\n",
        "\n",
        "    # MNIST 테스트 데이터에서 무작위로 하나를 뽑아서 예측을 해본다\n",
        "    r = random.randint(0, len(mnist_test) - 1)\n",
        "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
        "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
        "\n",
        "    print('Label: ', Y_single_data.item())\n",
        "    single_prediction = linear(X_single_data)\n",
        "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
        "\n",
        "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "TdTASVglmqWn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}