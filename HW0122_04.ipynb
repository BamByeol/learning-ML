{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW0122_04.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2yeaYiGqJuvPbaH8fCGS7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BamByeol/learning-ML/blob/HW220122/HW0122_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이토치로 다중 로지스틱 회귀 구현하기 04.01\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "id": "4iP2T8NAxL5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_set\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "metadata": {
        "id": "iqUj93mSxOlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 초기화\n",
        "W = torch.zeros((2, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W) + b) \n",
        "    # 파이토치에서 제공하는 exponential e의 함수를 사용하여 세운 가설은 아래와 같다.\n",
        "    # hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b)))\n",
        "    \n",
        "    cost = -(y_train * torch.log(hypothesis) + \n",
        "             (1 - y_train) * torch.log(1 - hypothesis)).mean()\n",
        "    \n",
        "    #파이토치에서 제공하는 로지스틱회귀의 비용함수\n",
        "    #F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "id": "eWRrwK3XxR_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습한 w와 b를 가지고 예측값 출력 => 이값은 모두 0과 1 사이의 값을 가지고 있음.\n",
        "hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "id": "YymxOHco-0zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#예측값을 가지고 0.5를 기준으로 넘으면 true, 넘지 못하지면 false를 출력\n",
        "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "print(prediction)\n",
        "\n",
        "#학습한 이후의 w과 b의 값\n",
        "print(W)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "7BSLrB7myEWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Module로 구현하는 로지스틱 회귀 04.02\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)\n",
        "\n",
        "model = nn.Sequential(\n",
        "   nn.Linear(2, 1), # input_dim = 2, output_dim = 1\n",
        "   nn.Sigmoid() # 출력은 시그모이드 함수를 거친다\n",
        ")\n",
        "\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 10번마다 로그 출력\n",
        "    if epoch % 10 == 0:\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
        "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
        "        ))\n",
        "\n",
        "#예측값확인\n",
        "#model(x_train)\n",
        "\n",
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "id": "MQQnB3lpCUY4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}